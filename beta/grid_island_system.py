#!/usr/bin/env python3
"""
Grid Island ìµœì¢… ì‹œìŠ¤í…œ: IMU â†’ ê·¸ë˜í”„ ê²½ë¡œ ìµœì í™”
ì™„ì „í•œ ì›í´ë¦­ ì†”ë£¨ì…˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
import heapq
from final_improved_model import FinalImprovedModel
from utils.data_loader import load_sensor_data, combine_sensor_data

class GridIslandSystem:
    """Grid Island ì™„ì „ í†µí•© ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.pipeline = FinalImprovedModel()
        self.nodes_df = None
        self.edges_df = None
        self.adjacency_list = None
        self.is_trained = False

    def setup_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸° ì„¤ì • (ëª¨ë¸ í•™ìŠµ í¬í•¨)"""
        print("ğŸš€ Grid Island ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print("="*50)

        # ëª¨ë¸ì´ ì´ë¯¸ í•™ìŠµë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        model_path = 'models/production_pipeline.pkl'
        if os.path.exists(model_path):
            try:
                self.pipeline.load_artifacts(model_path)
                self.is_trained = True
                print("âœ… ê¸°ì¡´ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except:
                print("âš ï¸  ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤...")
                self.train_model()
        else:
            print("ğŸ“š ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            self.train_model()

    def train_model(self):
        """ëª¨ë¸ í•™ìŠµ"""
        performance = self.pipeline.train_optimized_model()
        self.is_trained = True
        print(f"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (F1: {performance:.4f})")

    def process_imu_data(self, data_dir="test 2025-09-22 18-30-21"):
        """IMU ë°ì´í„° ì²˜ë¦¬í•˜ì—¬ ê·¸ë˜í”„ ìƒì„±"""
        if not self.is_trained:
            raise ValueError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. setup_system()ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

        print(f"ğŸ“Š IMU ë°ì´í„° ì²˜ë¦¬: {data_dir}")

        # ì„¼ì„œ ë°ì´í„° ë¡œë“œ
        sensor_data = load_sensor_data(data_dir)
        combined_df = combine_sensor_data(sensor_data)

        # ì˜¨ë¼ì¸ ì¶”ë¡ 
        results = self.pipeline.online_infer(combined_df)

        if results is None:
            print("âŒ ì¶”ë¡  ì‹¤íŒ¨")
            return False

        # ê·¸ë˜í”„ ë°ì´í„° ìƒì„±
        self._create_graph_from_results(results)

        print(f"âœ… ê·¸ë˜í”„ ìƒì„±: {len(self.nodes_df)}ê°œ ë…¸ë“œ, {len(self.edges_df)}ê°œ ì—£ì§€")
        return True

    def _create_graph_from_results(self, results):
        """ê²°ê³¼ì—ì„œ ê·¸ë˜í”„ ë°ì´í„° ìƒì„±"""
        positions = results['positions']
        difficulty_smoothed = results['difficulty_smoothed']
        edge_costs = results['edge_costs']
        probabilities = results['probabilities']

        # ë…¸ë“œ ìƒì„±
        nodes = []
        for i, (start, end) in enumerate(positions):
            node = {
                'node_id': i,
                'start_sample': start,
                'end_sample': end,
                'center_sample': (start + end) // 2,
                'difficulty': int(difficulty_smoothed[i]),
                'difficulty_name': self.pipeline.difficulty_map[difficulty_smoothed[i]],
                'confidence': float(probabilities[i].max()),
                'base_cost': float(edge_costs[i])
            }
            nodes.append(node)

        # ì—£ì§€ ìƒì„± (ë‹¤ì–‘í•œ ì—°ê²° íŒ¨í„´)
        edges = []
        edge_id = 0

        # 1. ìˆœì°¨ì  ì—°ê²° (ê¸°ë³¸ ê²½ë¡œ)
        for i in range(len(nodes) - 1):
            current = nodes[i]
            next_node = nodes[i + 1]

            edge = {
                'edge_id': edge_id,
                'from_node': current['node_id'],
                'to_node': next_node['node_id'],
                'cost': (current['base_cost'] + next_node['base_cost']) / 2,
                'distance': abs(next_node['center_sample'] - current['center_sample']),
                'difficulty_avg': (current['difficulty'] + next_node['difficulty']) / 2,
                'edge_type': 'sequential'
            }
            edges.append(edge)
            edge_id += 1

        # 2. ê±´ë„ˆë›°ê¸° ì—°ê²° (ìš°íšŒ ê²½ë¡œ)
        for jump in [2, 3, 5]:  # 2, 3, 5 ë…¸ë“œ ê±´ë„ˆë›°ê¸°
            for i in range(len(nodes) - jump):
                current = nodes[i]
                target = nodes[i + jump]

                # ê±´ë„ˆë›°ê¸° í˜ë„í‹° ì ìš©
                jump_penalty = 1.0 + (jump - 1) * 0.1  # ë©€ìˆ˜ë¡ ì•½ê°„ì˜ í˜ë„í‹°

                edge = {
                    'edge_id': edge_id,
                    'from_node': current['node_id'],
                    'to_node': target['node_id'],
                    'cost': (current['base_cost'] + target['base_cost']) / 2 * jump_penalty,
                    'distance': abs(target['center_sample'] - current['center_sample']),
                    'difficulty_avg': (current['difficulty'] + target['difficulty']) / 2,
                    'edge_type': f'jump_{jump}'
                }
                edges.append(edge)
                edge_id += 1

        self.nodes_df = pd.DataFrame(nodes)
        self.edges_df = pd.DataFrame(edges)

        # ì¸ì ‘ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        self._build_adjacency_list()

    def _build_adjacency_list(self):
        """ê·¸ë˜í”„ì˜ ì¸ì ‘ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±"""
        self.adjacency_list = {}

        for _, edge in self.edges_df.iterrows():
            from_node = edge['from_node']
            to_node = edge['to_node']
            cost = edge['cost']

            if from_node not in self.adjacency_list:
                self.adjacency_list[from_node] = []

            self.adjacency_list[from_node].append((to_node, cost))

    def find_optimal_path(self, start_node=0, end_node=None, preference='balanced'):
        """ìµœì  ê²½ë¡œ íƒìƒ‰ (ë‹¤ìµìŠ¤íŠ¸ë¼)"""
        if self.adjacency_list is None:
            print("âŒ ê·¸ë˜í”„ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        if end_node is None:
            end_node = len(self.nodes_df) - 1

        print(f"ğŸ—ºï¸  ê²½ë¡œ íƒìƒ‰: ë…¸ë“œ {start_node} â†’ ë…¸ë“œ {end_node} ({preference})")

        # ì„ í˜¸ë„ë³„ ê°€ì¤‘ì¹˜
        preferences = {
            'fastest': {'distance_weight': 1.0, 'difficulty_weight': 0.3},
            'balanced': {'distance_weight': 1.0, 'difficulty_weight': 1.0},
            'safest': {'distance_weight': 0.7, 'difficulty_weight': 2.0}
        }

        weights = preferences.get(preference, preferences['balanced'])

        # ë‹¤ìµìŠ¤íŠ¸ë¼ ì•Œê³ ë¦¬ì¦˜
        distances = {node: float('inf') for node in range(len(self.nodes_df))}
        distances[start_node] = 0
        previous = {}
        visited = set()

        pq = [(0, start_node)]

        while pq:
            current_dist, current_node = heapq.heappop(pq)

            if current_node in visited:
                continue

            visited.add(current_node)

            if current_node == end_node:
                break

            if current_node in self.adjacency_list:
                for neighbor, base_cost in self.adjacency_list[current_node]:
                    if neighbor in visited:
                        continue

                    # ì„ í˜¸ë„ ë°˜ì˜í•œ ë¹„ìš©
                    neighbor_difficulty = self.nodes_df.iloc[neighbor]['difficulty']
                    adjusted_cost = (base_cost * weights['distance_weight'] +
                                   neighbor_difficulty * 20 * weights['difficulty_weight'])

                    new_dist = current_dist + adjusted_cost

                    if new_dist < distances[neighbor]:
                        distances[neighbor] = new_dist
                        previous[neighbor] = current_node
                        heapq.heappush(pq, (new_dist, neighbor))

        # ê²½ë¡œ ì¬êµ¬ì„±
        if end_node not in previous and start_node != end_node:
            return None, None

        path = []
        current = end_node
        while current is not None:
            path.append(current)
            current = previous.get(current)

        path.reverse()

        # ê²½ë¡œ ë¶„ì„
        path_info = self._analyze_path(path, distances[end_node])

        return path, path_info

    def _analyze_path(self, path, total_cost):
        """ê²½ë¡œ ë¶„ì„"""
        if len(path) < 2:
            return {'total_cost': total_cost, 'segments': 0, 'difficulties': {}}

        path_nodes = self.nodes_df.iloc[path]

        difficulty_counts = path_nodes['difficulty'].value_counts().to_dict()
        total_distance = path_nodes.iloc[-1]['center_sample'] - path_nodes.iloc[0]['center_sample']

        path_info = {
            'total_cost': total_cost,
            'total_distance': total_distance,
            'segments': len(path),
            'avg_confidence': path_nodes['confidence'].mean(),
            'difficulty_distribution': {
                self.pipeline.difficulty_map[k]: v
                for k, v in difficulty_counts.items()
            }
        }

        return path_info

    def run_complete_analysis(self, data_dir="test 2025-09-22 18-30-21"):
        """ì™„ì „í•œ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸ¯ Grid Island ì™„ì „ ë¶„ì„ ì‹œìŠ¤í…œ")
        print("="*60)

        # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if not self.is_trained:
            self.setup_system()

        # 2. IMU ë°ì´í„° ì²˜ë¦¬
        success = self.process_imu_data(data_dir)
        if not success:
            return False

        # 3. ê²½ë¡œ ë¹„êµ
        preferences = ['fastest', 'balanced', 'safest']
        results = {}

        print(f"\nğŸ” ê²½ë¡œ ì˜µì…˜ ë¶„ì„")
        print("-"*40)

        for pref in preferences:
            path, info = self.find_optimal_path(preference=pref)
            if path and info:
                results[pref] = {'path': path, 'info': info}

                print(f"\n[{pref.upper()} ê²½ë¡œ]")
                print(f"  ì´ ë¹„ìš©: {info['total_cost']:.1f}")
                print(f"  ì„¸ê·¸ë¨¼íŠ¸: {info['segments']}ê°œ")
                print(f"  ì‹ ë¢°ë„: {info['avg_confidence']:.3f}")

                for difficulty, count in info['difficulty_distribution'].items():
                    print(f"  {difficulty}: {count}ê°œ")

        # 4. ë°ì´í„° ì €ì¥
        self.save_results()

        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ê·¸ë˜í”„: {len(self.nodes_df)}ê°œ ë…¸ë“œ, {len(self.edges_df)}ê°œ ì—£ì§€")
        print(f"ğŸ“ ê²°ê³¼: results/ í´ë” í™•ì¸")

        return results

    def save_results(self, output_dir="results"):
        """ê²°ê³¼ ì €ì¥"""
        os.makedirs(output_dir, exist_ok=True)

        if self.nodes_df is not None:
            self.nodes_df.to_csv(f"{output_dir}/grid_island_nodes.csv", index=False)

        if self.edges_df is not None:
            self.edges_df.to_csv(f"{output_dir}/grid_island_edges.csv", index=False)

        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_dir}/")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    system = GridIslandSystem()
    results = system.run_complete_analysis()

    if results:
        print(f"\nâœ… Grid Island ì‹œìŠ¤í…œ ì‹¤í–‰ ì„±ê³µ!")
        print(f"ğŸ¯ {len(results)}ê°€ì§€ ê²½ë¡œ ì˜µì…˜ ì œê³µ")
    else:
        print("âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()