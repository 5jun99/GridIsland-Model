#!/usr/bin/env python3
"""
ì™„ì „í•œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ v2.0
ë°ì´í„° ë¡œë”© â†’ íŠ¹ì„± ì¶”ì¶œ â†’ í´ëŸ¬ìŠ¤í„°ë§ â†’ ë‚œì´ë„ í‰ê°€ â†’ íœ ì²´ì–´ ì ‘ê·¼ì„± ë¶„ì„ â†’ ì¢…í•© ë³´ê³ ì„œ
"""

import os
import sys
import pandas as pd
import numpy as np
from utils.data_loader import load_sensor_data, combine_sensor_data, get_data_info
from feature_extractor import FeatureExtractor
from clustering_analyzer import ClusteringAnalyzer
from difficulty_analyzer import DifficultyAnalyzer

def main():
    """ì™„ì „í•œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ v2.0"""
    print("ğŸŒŠ Grid Island - ì™„ì „í•œ íœ ì²´ì–´ ì ‘ê·¼ì„± ë¶„ì„ ì‹œìŠ¤í…œ v2.0")
    print("ğŸ¯ íŠ¹ì„± ì¶”ì¶œ â†’ í´ëŸ¬ìŠ¤í„°ë§ â†’ ë‚œì´ë„ í‰ê°€ â†’ íœ ì²´ì–´ ì ‘ê·¼ì„± ë¶„ì„ â†’ ì¢…í•© ë³´ê³ ì„œ")
    print("=" * 75)

    # ê²°ê³¼ í´ë” ìƒì„±
    os.makedirs("results", exist_ok=True)

    # 1ë‹¨ê³„: ì„¼ì„œ ë°ì´í„° ì²˜ë¦¬
    print("\nğŸ“Š 1ë‹¨ê³„: ê³ ê¸‰ ì„¼ì„œ ë°ì´í„° ì²˜ë¦¬")
    print("-" * 45)

    data_dir = "data/test 2025-09-22 18-30-21"
    sensor_data = load_sensor_data(data_dir)

    if not sensor_data:
        print("âŒ ì„¼ì„œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        return False

    combined_df = combine_sensor_data(sensor_data)
    data_info = get_data_info(combined_df)

    print(f"ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ í‰ê°€:")
    print(f"  ìƒ˜í”Œë§ í’ˆì§ˆ: {'ìš°ìˆ˜' if data_info['sampling_rate_hz'] > 45 else 'ë³´í†µ'}")
    print(f"  ë°ì´í„° ì™„ì„±ë„: {(len(combined_df)/data_info['total_samples']*100):.1f}%")

    # 2ë‹¨ê³„: ê³ ê¸‰ íŠ¹ì„± ì¶”ì¶œ
    print("\nğŸ” 2ë‹¨ê³„: 55ì°¨ì› íŠ¹ì„± ì¶”ì¶œ ë° ì—”ì§€ë‹ˆì–´ë§")
    print("-" * 50)

    extractor = FeatureExtractor(window_size=200, overlap_ratio=0.75)
    features_df, window_positions = extractor.process_data(combined_df)

    # íŠ¹ì„± í’ˆì§ˆ í‰ê°€
    feature_quality = {
        'completeness': features_df.isnull().sum().sum() / (len(features_df) * len(features_df.columns)),
        'variance_ratio': len(features_df.columns[features_df.var() > 0.001]) / len(features_df.columns)
    }

    print(f"ğŸ“Š íŠ¹ì„± í’ˆì§ˆ í‰ê°€:")
    print(f"  íŠ¹ì„± ì™„ì„±ë„: {(1-feature_quality['completeness'])*100:.1f}%")
    print(f"  ìœ ì˜ë¯¸ íŠ¹ì„± ë¹„ìœ¨: {feature_quality['variance_ratio']*100:.1f}%")

    features_path = "results/extracted_features.csv"
    features_df.to_csv(features_path, index=False)

    # 3ë‹¨ê³„: ì§€ëŠ¥í˜• í´ëŸ¬ìŠ¤í„°ë§
    print("\nğŸ¯ 3ë‹¨ê³„: ì ì‘í˜• í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„")
    print("-" * 40)

    analyzer = ClusteringAnalyzer()
    analyzer.load_features(features_path)
    features_scaled = analyzer.preprocess_features()
    features_pca = analyzer.apply_pca(n_components=10)

    # ë‹¤ì¤‘ ë°©ë²•ë¡  ì ìš©
    methods = ['kmeans', 'gmm']
    best_result = None
    best_score = -1

    for method in methods:
        optimization_results = analyzer.find_optimal_clusters(max_k=8, method=method)
        max_silhouette = max(optimization_results['silhouette'])
        if max_silhouette > best_score:
            best_score = max_silhouette
            best_result = (method, optimization_results)

    method, optimization_results = best_result
    optimal_k = optimization_results['k_values'][np.argmax(optimization_results['silhouette'])]

    print(f"ğŸ† ìµœì  ë°©ë²•ë¡ : {method.upper()}, K={optimal_k} (í’ˆì§ˆ: {best_score:.3f})")

    labels = analyzer.perform_clustering(n_clusters=optimal_k, method=method)
    cluster_characteristics = analyzer.analyze_cluster_characteristics(labels)

    # ê²°ê³¼ ì €ì¥
    result_df = features_df.copy()
    result_df['cluster'] = labels
    result_df.to_csv("results/clustered_features.csv", index=False)
    cluster_characteristics.to_csv("results/cluster_characteristics.csv", index=False)

    # 4ë‹¨ê³„: ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ
    print("\nğŸ¥ 4ë‹¨ê³„: ì¢…í•© ë‚œì´ë„ ë° ì ‘ê·¼ì„± í‰ê°€")
    print("-" * 45)

    difficulty_analyzer = DifficultyAnalyzer()
    difficulty_analyzer.load_cluster_data("results/cluster_characteristics.csv")
    difficulty_results = difficulty_analyzer.analyze_all_clusters()

    # 5ë‹¨ê³„: ì§€ëŠ¥í˜• ë³´ê³ ì„œ ìƒì„±
    print("\nğŸ“‹ 5ë‹¨ê³„: ì§€ëŠ¥í˜• ë¶„ì„ ë³´ê³ ì„œ ìƒì„±")
    print("-" * 40)

    # ì „ì²´ ê²½ë¡œ ìœ„í—˜ë„ í‰ê°€
    weighted_accessibility = (difficulty_results['wheelchair_score'] * difficulty_results['percentage'] / 100).sum()
    weighted_difficulty = (difficulty_results['difficulty_score'] * difficulty_results['percentage'] / 100).sum()

    # ìœ„í—˜ êµ¬ê°„ ì‹ë³„
    high_risk_clusters = difficulty_results[difficulty_results['wheelchair_score'] < 0.4]
    safe_clusters = difficulty_results[difficulty_results['wheelchair_score'] >= 0.6]

    # ì¢…í•© ë“±ê¸‰ ê²°ì •
    if weighted_accessibility >= 0.7:
        overall_grade = "A (ìš°ìˆ˜)"
        recommendation = "íœ ì²´ì–´ ì´ìš©ì— ë§¤ìš° ì í•©í•œ ê²½ë¡œì…ë‹ˆë‹¤"
        emoji = "âœ…"
    elif weighted_accessibility >= 0.5:
        overall_grade = "B (ì–‘í˜¸)"
        recommendation = "íœ ì²´ì–´ ì´ìš©ì— ì í•©í•œ ê²½ë¡œì…ë‹ˆë‹¤"
        emoji = "âœ…"
    elif weighted_accessibility >= 0.3:
        overall_grade = "C (ë³´í†µ)"
        recommendation = "íœ ì²´ì–´ ì´ìš© ì‹œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
        emoji = "âš ï¸"
    elif weighted_accessibility >= 0.15:
        overall_grade = "D (ì£¼ì˜)"
        recommendation = "íœ ì²´ì–´ ì´ìš©ì´ ì–´ë µìŠµë‹ˆë‹¤. ëŒ€ì•ˆ ê²½ë¡œë¥¼ ê³ ë ¤í•˜ì„¸ìš”"
        emoji = "âŒ"
    else:
        overall_grade = "F (ìœ„í—˜)"
        recommendation = "íœ ì²´ì–´ ì´ìš©ì´ ë§¤ìš° ìœ„í—˜í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ê²½ë¡œë¥¼ ì´ìš©í•˜ì„¸ìš”"
        emoji = "ğŸš«"

    # ìƒì„¸ ë³´ê³ ì„œ ìƒì„±
    detailed_report = difficulty_analyzer.generate_report(difficulty_results)

    # ê²°ê³¼ ì €ì¥
    difficulty_results.to_csv("results/difficulty_analysis.csv", index=False)
    with open("results/comprehensive_report.txt", "w", encoding="utf-8") as f:
        f.write(detailed_report)

    # ì‹œê°í™”
    try:
        import matplotlib
        matplotlib.use('Agg')
        analyzer.visualize_clusters(labels, save_path="results/clustering_visualization.png")
        difficulty_analyzer.visualize_analysis(difficulty_results, save_path="results/accessibility_analysis.png")
    except Exception as e:
        print(f"âš ï¸  ì‹œê°í™” ì €ì¥ ì‹¤íŒ¨: {e}")

    # ìµœì¢… ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ‰ Grid Island ì™„ì „ ë¶„ì„ ì™„ë£Œ!")
    print("=" * 60)

    print(f"\nğŸ“Š ê²½ë¡œ ì¢…í•© í‰ê°€:")
    print(f"  {emoji} ì¢…í•© ë“±ê¸‰: {overall_grade}")
    print(f"  ğŸ“ˆ ì ‘ê·¼ì„± ì ìˆ˜: {weighted_accessibility:.3f}/1.0")
    print(f"  ğŸ”¥ ë‚œì´ë„ ì ìˆ˜: {weighted_difficulty:.3f}/1.0")
    print(f"  ğŸ’¡ ê¶Œì¥ì‚¬í•­: {recommendation}")

    print(f"\nğŸ¯ êµ¬ê°„ë³„ ìƒì„¸ ë¶„ì„:")
    for idx, row in difficulty_results.iterrows():
        risk_emoji = "âœ…" if row.wheelchair_score >= 0.6 else "âš ï¸" if row.wheelchair_score >= 0.4 else "âŒ"
        print(f"  {risk_emoji} í´ëŸ¬ìŠ¤í„° {row.cluster}: {row.wheelchair_grade}ë“±ê¸‰ ({row.percentage:.1f}%) - {row.wheelchair_name}")

    if len(high_risk_clusters) > 0:
        print(f"\nâš ï¸  ì£¼ì˜ êµ¬ê°„ ({len(high_risk_clusters)}ê°œ):")
        total_risk_percentage = high_risk_clusters['percentage'].sum()
        print(f"  ì „ì²´ ê²½ë¡œì˜ {total_risk_percentage:.1f}%ê°€ ìœ„í—˜ êµ¬ê°„ì…ë‹ˆë‹¤")
        for idx, row in high_risk_clusters.iterrows():
            print(f"  - í´ëŸ¬ìŠ¤í„° {row.cluster}: {row.wheelchair_description}")

    if len(safe_clusters) > 0:
        print(f"\nâœ… ì•ˆì „ êµ¬ê°„ ({len(safe_clusters)}ê°œ):")
        total_safe_percentage = safe_clusters['percentage'].sum()
        print(f"  ì „ì²´ ê²½ë¡œì˜ {total_safe_percentage:.1f}%ê°€ ì•ˆì „ êµ¬ê°„ì…ë‹ˆë‹¤")

    print(f"\nğŸ“ ìƒì„±ëœ ê²°ê³¼ íŒŒì¼:")
    result_files = [
        "results/extracted_features.csv",
        "results/clustered_features.csv",
        "results/cluster_characteristics.csv",
        "results/difficulty_analysis.csv",
        "results/comprehensive_report.txt",
        "results/clustering_visualization.png",
        "results/accessibility_analysis.png"
    ]

    for file in result_files:
        if os.path.exists(file):
            file_size = os.path.getsize(file) / 1024  # KB
            print(f"  âœ… {file} ({file_size:.1f} KB)")
        else:
            print(f"  âŒ {file}")

    return True

if __name__ == "__main__":
    success = main()
    if success:
        print(f"\nğŸŠ ë¶„ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ! ìƒì„¸ ê²°ê³¼ëŠ” results/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    else:
        print(f"\nğŸ’¥ ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")