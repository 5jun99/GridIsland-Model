#!/usr/bin/env python3
"""
í–¥ìƒëœ GPS ë°ì´í„° ë¡œë” - ê¸°ì¡´ feature_extractorì™€ clustering_analyzer, difficulty_analyzer í†µí•©
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Optional
import os
from pathlib import Path

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from feature_extractor import FeatureExtractor
from clustering_analyzer import ClusteringAnalyzer
from difficulty_analyzer import DifficultyAnalyzer

class EnhancedGPSLoader:
    """ê¸°ì¡´ ë¶„ì„ ì‹œìŠ¤í…œê³¼ í†µí•©ëœ GPS ë°ì´í„° ë¡œë”"""
    
    def __init__(self, data_path: str):
        self.data_path = Path(data_path)
        self.gps_data = None
        self.sensor_data = {}
        self.synchronized_data = None
        self.extracted_features = None
        self.clustered_data = None
        self.difficulty_results = None
        
        # ê¸°ì¡´ ë¶„ì„ê¸°ë“¤ ì´ˆê¸°í™”
        self.feature_extractor = FeatureExtractor()
        self.clustering_analyzer = ClusteringAnalyzer()
        self.difficulty_analyzer = DifficultyAnalyzer()
    
    def load_gps_data(self) -> pd.DataFrame:
        """GPS ìœ„ì¹˜ ë°ì´í„° ë¡œë“œ"""
        gps_file = self.data_path / "Location.csv"
        
        if not gps_file.exists():
            raise FileNotFoundError(f"GPS ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {gps_file}")
        
        print(f"ğŸ“ GPS ë°ì´í„° ë¡œë“œ: {gps_file}")
        
        self.gps_data = pd.read_csv(gps_file)
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        self.gps_data.columns = [
            'time_s', 'latitude', 'longitude', 'height_m', 
            'velocity_ms', 'direction_deg', 'h_accuracy_m', 'v_accuracy_deg'
        ]
        
        # NaN ê°’ ì²˜ë¦¬
        self.gps_data['velocity_ms'] = self.gps_data['velocity_ms'].fillna(0)
        self.gps_data['direction_deg'] = self.gps_data['direction_deg'].fillna(0)
        
        print(f"âœ… GPS ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.gps_data)}ê°œ í¬ì¸íŠ¸")
        
        return self.gps_data
    
    def load_sensor_data(self, sensors: List[str] = None) -> Dict[str, pd.DataFrame]:
        """ì„¼ì„œ ë°ì´í„° ë¡œë“œ"""
        if sensors is None:
            sensors = ['Accelerometer', 'Gyroscope', 'Linear Accelerometer', 'Gravity']
        
        self.sensor_data = {}
        
        for sensor in sensors:
            sensor_file = self.data_path / f"{sensor}.csv"
            
            if sensor_file.exists():
                print(f"ğŸ“± {sensor} ë°ì´í„° ë¡œë“œ...")
                
                df = pd.read_csv(sensor_file)
                
                # ì»¬ëŸ¼ëª… ì •ë¦¬ (ì›ë³¸ ì»¬ëŸ¼ëª… í™•ì¸)
                original_columns = df.columns.tolist()
                print(f"     ì›ë³¸ ì»¬ëŸ¼ëª…: {original_columns}")
                
                if sensor == 'Accelerometer':
                    df.columns = ['time_s', 'acc_x', 'acc_y', 'acc_z']
                elif sensor == 'Gyroscope':
                    df.columns = ['time_s', 'gyro_x', 'gyro_y', 'gyro_z']
                elif sensor == 'Linear Accelerometer':
                    df.columns = ['time_s', 'lin_acc_x', 'lin_acc_y', 'lin_acc_z']
                elif sensor == 'Gravity':
                    df.columns = ['time_s', 'grav_x', 'grav_y', 'grav_z']
                
                self.sensor_data[sensor] = df
                print(f"   ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ")
            else:
                print(f"âš ï¸  {sensor} ë°ì´í„° íŒŒì¼ ì—†ìŒ")
        
        return self.sensor_data
    
    def synchronize_data(self, window_size: float = 1.0) -> pd.DataFrame:
        """GPSì™€ ì„¼ì„œ ë°ì´í„°ë¥¼ ì‹œê°„ ìœˆë„ìš°ë³„ë¡œ ë™ê¸°í™”"""
        if self.gps_data is None:
            raise ValueError("GPS ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”")
        
        if not self.sensor_data:
            raise ValueError("ì„¼ì„œ ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”")
        
        print(f"ğŸ”„ ë°ì´í„° ë™ê¸°í™” ì‹œì‘ (ìœˆë„ìš° í¬ê¸°: {window_size}ì´ˆ)")
        
        # ì „ì²´ ì‹œê°„ ë²”ìœ„ í™•ì¸
        gps_time_range = (self.gps_data['time_s'].min(), self.gps_data['time_s'].max())
        
        sensor_time_ranges = {}
        for sensor, df in self.sensor_data.items():
            sensor_time_ranges[sensor] = (df['time_s'].min(), df['time_s'].max())
        
        # ê³µí†µ ì‹œê°„ ë²”ìœ„ ê³„ì‚°
        start_time = max([gps_time_range[0]] + [r[0] for r in sensor_time_ranges.values()])
        end_time = min([gps_time_range[1]] + [r[1] for r in sensor_time_ranges.values()])
        
        print(f"   ê³µí†µ ì‹œê°„ ë²”ìœ„: {start_time:.1f}s ~ {end_time:.1f}s")
        
        # ìœˆë„ìš°ë³„ ë°ì´í„° ìƒì„±
        synchronized_records = []
        
        current_time = start_time
        window_id = 0
        
        while current_time + window_size <= end_time:
            window_end = current_time + window_size
            
            # GPS ë°ì´í„° ìœˆë„ìš° ì¶”ì¶œ
            gps_window = self.gps_data[
                (self.gps_data['time_s'] >= current_time) & 
                (self.gps_data['time_s'] < window_end)
            ]
            
            if len(gps_window) == 0:
                current_time += window_size
                continue
            
            # GPS í•µì‹¬ ì •ë³´ë§Œ ê³„ì‚° (ìœ„ì¹˜, ì†ë„, ê³ ë„)
            gps_stats = {
                'window_id': window_id,
                'start_time': current_time,
                'end_time': window_end,
                'duration': window_size,
                'gps_count': len(gps_window),
                'lat_mean': gps_window['latitude'].mean(),
                'lng_mean': gps_window['longitude'].mean(),
                'height_mean': gps_window['height_m'].mean(),
                'velocity_mean': gps_window['velocity_ms'].mean(),
                'direction_mean': gps_window['direction_deg'].mean()
            }
            
            synchronized_records.append(gps_stats)
            
            current_time += window_size
            window_id += 1
        
        self.synchronized_data = pd.DataFrame(synchronized_records)
        
        print(f"âœ… ë™ê¸°í™” ì™„ë£Œ: {len(self.synchronized_data)}ê°œ ìœˆë„ìš°")
        
        return self.synchronized_data
    
    def extract_advanced_features(self, window_size: int = 200, overlap_ratio: float = 0.75) -> pd.DataFrame:
        """ê¸°ì¡´ feature_extractorë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ê¸‰ íŠ¹ì„± ì¶”ì¶œ"""
        if not self.sensor_data:
            raise ValueError("ì„¼ì„œ ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”")
        
        print(f"ğŸ” ê³ ê¸‰ íŠ¹ì„± ì¶”ì¶œ ì‹œì‘ (ìœˆë„ìš°: {window_size}, ì˜¤ë²„ë©: {overlap_ratio})")
        
        # ì„¼ì„œ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ í†µí•© (ê¸°ì¡´ feature_extractorê°€ DataFrameì„ ë°›ìŒ)
        # ê°€ì†ë„ê³„ì™€ ìì´ë¡œìŠ¤ì½”í”„ ë°ì´í„° ê²°í•©
        if 'Accelerometer' in self.sensor_data and 'Gyroscope' in self.sensor_data:
            acc_data = self.sensor_data['Accelerometer']
            gyro_data = self.sensor_data['Gyroscope']
            
            print(f"   ê°€ì†ë„ê³„ ì‹œê°„ ë²”ìœ„: {acc_data['time_s'].min():.3f} ~ {acc_data['time_s'].max():.3f}")
            print(f"   ìì´ë¡œìŠ¤ì½”í”„ ì‹œê°„ ë²”ìœ„: {gyro_data['time_s'].min():.3f} ~ {gyro_data['time_s'].max():.3f}")
            
            # ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© (tolerance ëŠ˜ë ¤ì„œ ë” ë§ì€ ë§¤ì¹­ í—ˆìš©)
            merged_data = pd.merge_asof(
                acc_data.sort_values('time_s'), 
                gyro_data.sort_values('time_s'), 
                on='time_s', 
                tolerance=0.1,  # 100ms í—ˆìš© ì˜¤ì°¨ë¡œ ì¦ê°€
                suffixes=('', '_gyro')
            )
            
            # ìì´ë¡œ ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë³‘í•©ë˜ì—ˆëŠ”ì§€ í™•ì¸
            print(f"   ìì´ë¡œ ë°ì´í„° ìœ íš¨ì„±: {merged_data['gyro_x'].notna().sum()}/{len(merged_data)} ìƒ˜í”Œ")
            
            # ì»¬ëŸ¼ëª…ì„ ê¸°ì¡´ feature_extractor í˜•ì‹ì— ë§ê²Œ ë³€ê²½
            sensor_df = merged_data[['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']].copy()
            
            # ìì´ë¡œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì±„ìš°ê¸° (ëŒ€ì‹  ê²½ê³  ì¶œë ¥)
            if sensor_df['gyro_x'].isna().all():
                print("âš ï¸  ìì´ë¡œìŠ¤ì½”í”„ ë°ì´í„° ë³‘í•© ì‹¤íŒ¨ - 0ìœ¼ë¡œ ëŒ€ì²´")
                sensor_df[['gyro_x', 'gyro_y', 'gyro_z']] = 0.0
            
            print(f"   ë³‘í•©ëœ ì„¼ì„œ ë°ì´í„° í¬ê¸°: {len(sensor_df)}ê°œ ìƒ˜í”Œ")
            print(f"   ì„¼ì„œ ë°ì´í„° ë²”ìœ„: {sensor_df.index.min()} ~ {sensor_df.index.max()}")
            
            # ê¸°ì¡´ feature_extractorë¡œ íŠ¹ì„± ì¶”ì¶œ
            self.feature_extractor.window_size = window_size
            self.feature_extractor.overlap_ratio = overlap_ratio
            
            features_df, window_positions = self.feature_extractor.process_data(sensor_df)
            self.extracted_features = features_df
            
            print(f"âœ… íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {len(self.extracted_features)}ê°œ ìœˆë„ìš°, {len(self.extracted_features.columns)}ê°œ íŠ¹ì„±")
            
        else:
            raise ValueError("Accelerometerì™€ Gyroscope ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        return self.extracted_features
    
    def perform_clustering(self, n_clusters: int = None) -> pd.DataFrame:
        """ê¸°ì¡´ clustering_analyzerë¡œ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰"""
        if self.extracted_features is None:
            raise ValueError("íŠ¹ì„±ì„ ë¨¼ì € ì¶”ì¶œí•˜ì„¸ìš”")
        
        print(f"ğŸ¯ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ì‹œì‘")
        
        # íŠ¹ì„± ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì„ì‹œ ì €ì¥ (clustering_analyzerê°€ íŒŒì¼ì„ ì½ë„ë¡ ì„¤ê³„ë¨)
        temp_features_file = "temp_features.csv"
        
        # ë¹ˆ DataFrame ì²´í¬
        if self.extracted_features is None or len(self.extracted_features) == 0:
            print("âŒ ì¶”ì¶œëœ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤. ìœˆë„ìš° í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
            return None
        
        self.extracted_features.to_csv(temp_features_file, index=False)
        print(f"   ì„ì‹œ íŠ¹ì„± íŒŒì¼ ì €ì¥: {len(self.extracted_features)}ê°œ ìœˆë„ìš°")
        
        # clustering_analyzerë¡œ ë¶„ì„
        self.clustering_analyzer.load_features(temp_features_file)
        features_scaled = self.clustering_analyzer.preprocess_features()
        
        # í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„¤ì • (ë” ì„¸ë°€í•œ ë¶„ì„ì„ ìœ„í•´)
        if n_clusters is None:
            optimization_results = self.clustering_analyzer.find_optimal_clusters(max_k=10, method='kmeans')
            
            # Silhouette Score í™•ì¸í•˜ë˜, ìµœì†Œ 4ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ì„¤ì •
            best_k = optimization_results['k_values'][np.argmax(optimization_results['silhouette'])]
            
            # 4ê°œ ì´ìƒì˜ í´ëŸ¬ìŠ¤í„° ê°•ì œ (ë” ì„¸ë°€í•œ ë‚œì´ë„ êµ¬ë¶„)
            if best_k < 4:
                print(f"ğŸ“Š Silhouette ìµœì : {best_k}ê°œ â†’ ì„¸ë°€í•œ ë¶„ì„ì„ ìœ„í•´ 4ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ì¡°ì •")
                n_clusters = 4
            else:
                print(f"ğŸ“Š ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜: {best_k} (26ê°œ íŠ¹ì§• ê¸°ë°˜)")
                n_clusters = best_k
        
        # í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
        labels = self.clustering_analyzer.perform_clustering(n_clusters=n_clusters, method='kmeans')
        
        # ê²°ê³¼ë¥¼ ê¸°ì¡´ íŠ¹ì„± ë°ì´í„°ì— ì¶”ê°€
        self.clustered_data = self.extracted_features.copy()
        self.clustered_data['cluster'] = labels
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(temp_features_file):
            os.remove(temp_features_file)
        
        print(f"âœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {n_clusters}ê°œ í´ëŸ¬ìŠ¤í„°")
        
        return self.clustered_data
    
    def analyze_difficulty(self) -> pd.DataFrame:
        """ê¸°ì¡´ difficulty_analyzerë¡œ ë‚œì´ë„ ë¶„ì„"""
        if self.clustered_data is None:
            raise ValueError("í´ëŸ¬ìŠ¤í„°ë§ì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”")
        
        print(f"ğŸ” ë‚œì´ë„ ë¶„ì„ ì‹œì‘")
        
        # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ê³„ì‚°
        cluster_characteristics = []
        
        for cluster_id in sorted(self.clustered_data['cluster'].unique()):
            cluster_data = self.clustered_data[self.clustered_data['cluster'] == cluster_id]
            
            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
            numeric_cols = cluster_data.select_dtypes(include=[np.number]).columns
            exclude_cols = ['window_id', 'start_idx', 'end_idx', 'window_size', 'cluster']
            feature_cols = [col for col in numeric_cols if col not in exclude_cols]
            
            # í´ëŸ¬ìŠ¤í„°ë³„ í†µê³„ ê³„ì‚°
            cluster_stats = {
                'cluster': cluster_id,
                'count': len(cluster_data),
                'percentage': len(cluster_data) / len(self.clustered_data) * 100
            }
            
            # ê° íŠ¹ì„±ì˜ í‰ê· ê°’ ê³„ì‚°
            for col in feature_cols:
                cluster_stats[f'{col}_mean'] = cluster_data[col].mean()
            
            cluster_characteristics.append(cluster_stats)
        
        cluster_characteristics_df = pd.DataFrame(cluster_characteristics)
        
        # difficulty_analyzerë¡œ ë¶„ì„ (ì„ì‹œ íŒŒì¼ ì‚¬ìš©)
        temp_cluster_file = "temp_cluster_characteristics.csv"
        cluster_characteristics_df.to_csv(temp_cluster_file, index=False)
        
        self.difficulty_analyzer.load_cluster_data(temp_cluster_file)
        difficulty_results = self.difficulty_analyzer.analyze_all_clusters()
        
        self.difficulty_results = difficulty_results
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if os.path.exists(temp_cluster_file):
            os.remove(temp_cluster_file)
        
        print(f"âœ… ë‚œì´ë„ ë¶„ì„ ì™„ë£Œ")
        
        return difficulty_results
    
    def map_difficulty_to_gps(self) -> pd.DataFrame:
        """í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ë‚œì´ë„ë¥¼ GPS ìœˆë„ìš°ì— ë§¤í•‘"""
        if self.synchronized_data is None:
            raise ValueError("ë™ê¸°í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        if self.clustered_data is None or self.difficulty_results is None:
            raise ValueError("í´ëŸ¬ìŠ¤í„°ë§ê³¼ ë‚œì´ë„ ë¶„ì„ì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”")
        
        print(f"ğŸ—ºï¸  ë‚œì´ë„ë¥¼ GPS ìœˆë„ìš°ì— ë§¤í•‘ ì¤‘...")
        
        # GPS ìœˆë„ìš°ì™€ íŠ¹ì„± ì¶”ì¶œ ìœˆë„ìš° ë§¤í•‘
        gps_with_difficulty = self.synchronized_data.copy()
        
        # í´ëŸ¬ìŠ¤í„°ë³„ ë‚œì´ë„ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        cluster_difficulty_map = {}
        for _, row in self.difficulty_results.iterrows():
            cluster_id = row['cluster']
            cluster_difficulty_map[cluster_id] = {
                'difficulty_score': row['difficulty_score'],
                'difficulty_level': row['difficulty_level'],
                'difficulty_name': row['difficulty_name']
            }
        
        # GPS ìœˆë„ìš° ìˆ˜ì™€ íŠ¹ì„± ìœˆë„ìš° ìˆ˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë§¤í•‘ ì „ëµ í•„ìš”
        n_gps_windows = len(self.synchronized_data)
        n_feature_windows = len(self.clustered_data)
        
        print(f"   GPS ìœˆë„ìš°: {n_gps_windows}ê°œ, íŠ¹ì„± ìœˆë„ìš°: {n_feature_windows}ê°œ")
        
        # íŠ¹ì„± ìœˆë„ìš°ë¥¼ GPS ìœˆë„ìš°ì— ë§¤í•‘
        difficulty_scores = []
        cluster_ids = []
        difficulty_levels = []
        
        for i in range(n_gps_windows):
            # ë¹„ë¡€ ë§¤í•‘ (ì„ í˜• ë³´ê°„)
            feature_idx = int(i * (n_feature_windows - 1) / max(1, n_gps_windows - 1))
            feature_idx = min(feature_idx, n_feature_windows - 1)
            
            cluster_id = self.clustered_data.iloc[feature_idx]['cluster']
            
            if cluster_id in cluster_difficulty_map:
                cluster_info = cluster_difficulty_map[cluster_id]
                difficulty_scores.append(cluster_info['difficulty_score'])
                difficulty_levels.append(cluster_info['difficulty_level'])
            else:
                # ê¸°ë³¸ê°’
                difficulty_scores.append(0.5)
                difficulty_levels.append(2)
            
            cluster_ids.append(cluster_id)
        
        # GPS ë°ì´í„°ì— ë‚œì´ë„ ì •ë³´ ì¶”ê°€
        gps_with_difficulty['cluster_id'] = cluster_ids
        gps_with_difficulty['difficulty'] = difficulty_scores
        gps_with_difficulty['difficulty_level'] = difficulty_levels
        
        # ë‚œì´ë„ ë“±ê¸‰ ë¬¸ìì—´ ì¶”ê°€
        def get_difficulty_name(level):
            names = ['ë§¤ìš° ì‰¬ì›€', 'ì‰¬ì›€', 'ë³´í†µ', 'ì–´ë ¤ì›€', 'ë§¤ìš° ì–´ë ¤ì›€']
            return names[min(level, 4)]
        
        gps_with_difficulty['difficulty_name'] = gps_with_difficulty['difficulty_level'].apply(get_difficulty_name)
        
        self.synchronized_data = gps_with_difficulty
        
        print(f"âœ… ë‚œì´ë„ ë§¤í•‘ ì™„ë£Œ")
        print(f"   í‰ê·  ë‚œì´ë„: {np.mean(difficulty_scores):.3f}")
        
        return gps_with_difficulty
    
    def visualize_enhanced_data(self, save_path: str = None):
        """í–¥ìƒëœ ë°ì´í„° ì‹œê°í™”"""
        if self.synchronized_data is None:
            raise ValueError("ë§¤í•‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        df = self.synchronized_data
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        
        # 1. GPS ê²½ë¡œ (í´ëŸ¬ìŠ¤í„°ë³„)
        ax1 = axes[0, 0]
        scatter = ax1.scatter(df['lng_mean'], df['lat_mean'], 
                             c=df['cluster_id'], cmap='tab10', 
                             s=50, alpha=0.7)
        ax1.set_xlabel('Longitude')
        ax1.set_ylabel('Latitude')
        ax1.set_title('GPS Path (colored by cluster)')
        plt.colorbar(scatter, ax=ax1)
        
        # 2. GPS ê²½ë¡œ (ë‚œì´ë„ë³„)
        ax2 = axes[0, 1]
        scatter = ax2.scatter(df['lng_mean'], df['lat_mean'], 
                             c=df['difficulty'], cmap='Reds', 
                             s=50, alpha=0.7)
        ax2.set_xlabel('Longitude')
        ax2.set_ylabel('Latitude')
        ax2.set_title('GPS Path (colored by difficulty)')
        plt.colorbar(scatter, ax=ax2)
        
        # 3. GPS ê²½ë¡œ (ë‚œì´ë„ ë ˆë²¨ë³„)
        ax3 = axes[0, 2]
        scatter = ax3.scatter(df['lng_mean'], df['lat_mean'], 
                             c=df['difficulty_level'], cmap='RdYlGn_r', 
                             s=50, alpha=0.7)
        ax3.set_xlabel('Longitude')
        ax3.set_ylabel('Latitude')
        ax3.set_title('GPS Path (colored by difficulty level)')
        plt.colorbar(scatter, ax=ax3)
        
        # 4. ë‚œì´ë„ ì‹œê³„ì—´
        ax4 = axes[1, 0]
        ax4.plot(df['window_id'], df['difficulty'], 'r-', linewidth=2)
        ax4.set_xlabel('Window ID')
        ax4.set_ylabel('Difficulty Score')
        ax4.set_title('Difficulty Over Time')
        ax4.grid(True, alpha=0.3)
        
        # 5. ë‚œì´ë„ ë ˆë²¨ ì‹œê³„ì—´
        ax5 = axes[1, 1]
        ax5.plot(df['window_id'], df['difficulty_level'], 'o-', linewidth=2, markersize=4)
        ax5.set_xlabel('Window ID')
        ax5.set_ylabel('Difficulty Level')
        ax5.set_title('Difficulty Level Over Time')
        ax5.grid(True, alpha=0.3)
        
        # 6. í´ëŸ¬ìŠ¤í„° ë¶„í¬
        ax6 = axes[1, 2]
        cluster_counts = df['cluster_id'].value_counts().sort_index()
        ax6.bar(cluster_counts.index, cluster_counts.values, alpha=0.7)
        ax6.set_xlabel('Cluster ID')
        ax6.set_ylabel('Count')
        ax6.set_title('Cluster Distribution')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ ì‹œê°í™” ì €ì¥: {save_path}")
        
        plt.show()
    
    def save_results(self, base_path: str = "results"):
        """ê²°ê³¼ ì €ì¥"""
        os.makedirs(base_path, exist_ok=True)
        
        if self.extracted_features is not None:
            features_file = f"{base_path}/extracted_features.csv"
            self.extracted_features.to_csv(features_file, index=False)
            print(f"ğŸ’¾ íŠ¹ì„± ë°ì´í„° ì €ì¥: {features_file}")
        
        if self.clustered_data is not None:
            clustered_file = f"{base_path}/clustered_features.csv"
            self.clustered_data.to_csv(clustered_file, index=False)
            print(f"ğŸ’¾ í´ëŸ¬ìŠ¤í„° ë°ì´í„° ì €ì¥: {clustered_file}")
        
        if self.difficulty_results is not None:
            difficulty_file = f"{base_path}/difficulty_analysis.csv"
            self.difficulty_results.to_csv(difficulty_file, index=False)
            print(f"ğŸ’¾ ë‚œì´ë„ ë¶„ì„ ì €ì¥: {difficulty_file}")
        
        if self.synchronized_data is not None:
            synchronized_file = f"{base_path}/gps_synchronized.csv"
            self.synchronized_data.to_csv(synchronized_file, index=False)
            print(f"ğŸ’¾ í†µí•© GPS ë°ì´í„° ì €ì¥: {synchronized_file}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í–¥ìƒëœ GPS ë°ì´í„° ë¡œë” ì‹¤í–‰")
    print("=" * 60)
    
    try:
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        data_path = "data/Sss 2025-10-02 15-53-01"
        loader = EnhancedGPSLoader(data_path)
        
        # 1. GPS ë° ì„¼ì„œ ë°ì´í„° ë¡œë“œ
        gps_data = loader.load_gps_data()
        sensor_data = loader.load_sensor_data()
        
        # 2. ë°ì´í„° ë™ê¸°í™”
        synchronized_data = loader.synchronize_data(window_size=1.0)
        
        # 3. ìµœì í™”ëœ íŠ¹ì„± ì¶”ì¶œ (26ê°œ í•µì‹¬ íŠ¹ì§•)
        features = loader.extract_advanced_features(window_size=150, overlap_ratio=0.6)
        
        # 4. í´ëŸ¬ìŠ¤í„°ë§ (ê¸°ì¡´ clustering_analyzer í™œìš©)
        clustered_data = loader.perform_clustering()
        
        # 5. ë‚œì´ë„ ë¶„ì„ (ê¸°ì¡´ difficulty_analyzer í™œìš©)
        difficulty_results = loader.analyze_difficulty()
        
        # 6. GPSì— ë‚œì´ë„ ë§¤í•‘
        gps_with_difficulty = loader.map_difficulty_to_gps()
        
        # 7. ì‹œê°í™”
        loader.visualize_enhanced_data(save_path="results/enhanced_gps_analysis.png")
        
        # 8. ê²°ê³¼ ì €ì¥
        loader.save_results()
        
        print(f"\nâœ… í–¥ìƒëœ GPS ë¶„ì„ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()